{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6ZDoro4NSPy"
      },
      "source": [
        "<div style=\"color:white;\n",
        "            display:fill;\n",
        "            border-radius:20px;\n",
        "            background-color:green;\n",
        "            font-size:200%;\n",
        "            font-family:Verdana;\n",
        "            letter-spacing:1px\">\n",
        "    <h1 style='padding: 10px;\n",
        "               margin:0px auto 0px auto;\n",
        "              color:white;\n",
        "              text-align:center;'>\n",
        "       &nbsp;Depth Prediction with MiDaS\n",
        "    </h1>\n",
        "    </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7MuRdNPNSPz"
      },
      "source": [
        "## This the code for predicting the weight of waste present in the image.\n",
        "\n",
        "## just run the cells 1 by 1 and wait for the folders to form in the storage section.\n",
        "\n",
        "## Insert your images and yolo format annotaion file in anno_folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import time\n",
        "from PIL import Image\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "VHr4-XvmNzFi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 2 new folders\n",
        "os.makedirs('/content/annotated_files')\n",
        "\n",
        "os.makedirs('/content/midas_images')"
      ],
      "metadata": {
        "id": "970CLY-cdbiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --> The annotated_files folder can store the Input images and annotation files of the images. Make sure to keep the name of image and annotation file same.\n",
        "\n",
        "# --> The midas_images folder is system generated and is for the system only. Do not modify this folder"
      ],
      "metadata": {
        "id": "s1QWMxQ1d9w7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5xVEI2nNSPz",
        "outputId": "c5573294-9c9e-4d85-e1df-77efc3741ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (2.0.0+cu118)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.13.3 timm-0.6.13\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYunkvnINSP0",
        "outputId": "bd1ec9b5-79df-4cd4-e5e5-ccf90291deb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|██████████| 1.28G/1.28G [00:20<00:00, 65.6MB/s]\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAnSUUH4NSP0",
        "outputId": "2b4c67e0-d99e-452b-be47-783cf2e3f788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_2-000039.jpg\n"
          ]
        }
      ],
      "source": [
        "# Path to the folder containing YOLO annotated files\n",
        "anno_folder = '/content/annotated_files'\n",
        "\n",
        "# Path to the Midas depth image\n",
        "midas_img_path = '/content/midas_images'\n",
        "\n",
        "# Create an empty dictionary to store the results\n",
        "results = {}\n",
        "\n",
        "# Define the density of the material in cm^3/g (hand crafted)\n",
        "density = {'Aluminium foil': 2.7,'Battery': 1.5,'Aluminium blister pack':2.71,'Carded blister pack': 2.4,'Other plastic bottle': 1.6,'Clear plastic bottle': 1,'Glass bottle': 3.2,'Plastic bottle cap': 0.92,'Metal bottle cap': 1.3,'Broken glass': 3.2,'Food Can': 3.6,'Aerosol': 2,'Drink can': 1,'Toilet tube': 2.2,'Other carton': 1.6,'Egg carton': 1.4,'Drink carton': 1.7,'Corrugated carton': 0.5,'Meal carton': 1.4,'Pizza box': 1.8,'Paper cup': 0.8,'Disposable plastic cup': 0.8,'Foam cup':0.6,'Glass cup': 2.2,'Other plastic cup': 0.8,'Food waste': 1.4,'Glass jar':2.4,'Plastic lid': 0.8,'Metal lid': 1.2,'Other plastic': 0.9,'Magazine paper': 0.3,'Tissues': 0.3,'Wrapping paper': 0.5,'Normal paper': 0.7,'Paper bag':0.7,'Plastified paper bag': 0.7,'Plastic film' : 1.2,'Six pack rings': 1.3,'Garbage bag': 4,'Other plastic wrapper' : 1.2,'Single-use carrier bag': 1.2,'Polypropylene bag': 1.3,'Crisp packet': 2.2,'Spread tub' : 3.4,'Tupperware' : 4.2,'Disposable food container':2.7,'Foam food container': 1.7,'Other plastic container': 1.7,'Plastic glooves': 2.2,'Plastic utensils': 1.9,'Pop tab': 0.4,'Rope & strings': 0.2,'Scrap metal' : 4.3,'Shoe' : 3.8,'Squeezable tube': 1.7,'Plastic straw' : 0.8,'Paper straw': 0.6,'Styrofoam piece' : 2.2,'Unlabeled litter': 2,'Cigarette': 4.2}\n",
        "\n",
        "# Define a constant factor to scale the weight calculation (set according to comparitions of the results with the ground truth)\n",
        "scale_factor = 0.001\n",
        "\n",
        "# Initialize a variable to store the total weight of the image\n",
        "total_weight = 0\n",
        "\n",
        "# Loop through the annotated files in the folder\n",
        "for filename in os.listdir(anno_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Read input image\n",
        "        img = cv2.imread(os.path.join(anno_folder, filename))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        input_batch = transform(img).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = midas(input_batch)\n",
        "\n",
        "            prediction = torch.nn.functional.interpolate(\n",
        "                prediction.unsqueeze(1),\n",
        "                size=img.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "\n",
        "        output = prediction.cpu().numpy()\n",
        "        print(filename)\n",
        "\n",
        "        # Save output image\n",
        "        save_filename = os.path.join(midas_img_path, os.path.splitext(filename)[0] + '_midas')\n",
        "        plt.imsave(save_filename + '.png', output, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "density = {i+1: density[k] for i, k in enumerate(density)}\n",
        "print(density)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBt2IA2HlKAW",
        "outputId": "4003ea0c-1e6a-4161-9ce8-8c9c96981f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 2.7, 2: 1.5, 3: 2.71, 4: 2.4, 5: 1.6, 6: 1, 7: 3.2, 8: 0.92, 9: 1.3, 10: 3.2, 11: 3.6, 12: 2, 13: 1, 14: 2.2, 15: 1.6, 16: 1.4, 17: 1.7, 18: 0.5, 19: 1.4, 20: 1.8, 21: 0.8, 22: 0.8, 23: 0.6, 24: 2.2, 25: 0.8, 26: 1.4, 27: 2.4, 28: 0.8, 29: 1.2, 30: 0.9, 31: 0.3, 32: 0.3, 33: 0.5, 34: 0.7, 35: 0.7, 36: 0.7, 37: 1.2, 38: 1.3, 39: 4, 40: 1.2, 41: 1.2, 42: 1.3, 43: 2.2, 44: 3.4, 45: 4.2, 46: 2.7, 47: 1.7, 48: 1.7, 49: 2.2, 50: 1.9, 51: 0.4, 52: 0.2, 53: 4.3, 54: 3.8, 55: 1.7, 56: 0.8, 57: 0.6, 58: 2.2, 59: 2, 60: 4.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "density = {1: 2.7, 2: 1.5, 3: 2.71, 4: 2.4}\n",
        "factor = 0.00001\n",
        "\n",
        "class_weights = {}\n",
        "class_weight_sum = 0\n",
        "\n",
        "for filename in os.listdir(anno_folder):\n",
        "    if filename.endswith('.txt'):\n",
        "        # Load the annotation file\n",
        "        anno_file = os.path.join(anno_folder, filename)\n",
        "        with open(anno_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Extract the coordinates of all the annotated areas\n",
        "        class_coords = {}\n",
        "        img_file = os.path.join(anno_folder, filename.replace('.txt', '.jpg'))  # Assumes image file has the same name as label file, but with a .jpg extension\n",
        "        midas_file = os.path.join(midas_img_path, filename.replace('.txt', '_midas.png'))  # Assumes midas file has the same name as label file, but with a _midas.png extension\n",
        "        with Image.open(img_file) as img:\n",
        "            img_w, img_h = img.size\n",
        "        with open(os.path.join(anno_folder, filename), 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line != '':\n",
        "                class_id, x_center_norm, y_center_norm, w_norm, h_norm = [float(x) for x in line.split()]\n",
        "                x_center, y_center, w, h = int(x_center_norm * img_w), int(y_center_norm * img_h), int(w_norm * img_w), int(h_norm * img_h)\n",
        "                x1, y1, x2, y2 = x_center - w // 2, y_center - h // 2, x_center + w // 2, y_center + h // 2\n",
        "                print(class_id, x1, y1, x2, y2)\n",
        "            if class_id not in class_coords:\n",
        "               class_coords[class_id] = []\n",
        "               class_coords[class_id].append((x1, y1, x2, y2))\n",
        "\n",
        "        # Get the mode of the pixel values for each annotated area\n",
        "        for class_id, coords in class_coords.items():\n",
        "            mode_values = []\n",
        "            for coord in coords:\n",
        "              with Image.open(midas_file) as midas_img:\n",
        "                x1, y1, x2, y2 = coord\n",
        "                cropped_img = midas_img.crop((x1, y1, x2, y2))\n",
        "                cropped_arr = np.array(cropped_img)\n",
        "                mode_val = stats.mode(cropped_arr, axis=None).mode[0]\n",
        "                mode_values.append(mode_val)\n",
        "\n",
        "            # Calculate class weight\n",
        "            area = sum([(x2-x1)*(y2-y1) for (x1, y1, x2, y2) in coords])\n",
        "            density_val = density.get(class_id, 1)  # If class density not available, assume 1\n",
        "            class_weight = area * np.mean(mode_values) * density_val * factor\n",
        "            class_weights[class_id] = class_weight\n",
        "            class_weight_sum += class_weight\n",
        "\n",
        "print(\"Class weights:\", class_weights)\n",
        "print(\"Class weight sum:\", class_weight_sum, \"grams\")"
      ],
      "metadata": {
        "id": "WOxLTfItkkfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657df8ed-55ac-4380-e248-64bfb533431b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 1069 1403 1269 1623\n",
            "58.0 1238 730 1316 806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-45243bf3305b>:41: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode_val = stats.mode(cropped_arr, axis=None).mode[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {12.0: 112.2, 58.0: 1.8376800000000002}\n",
            "Class weight sum: 114.03768000000001 grams\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyooNWHlU0h1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}